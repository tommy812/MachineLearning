{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "-TQu2i9rDhMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method 1"
      ],
      "metadata": {
        "id": "NhTjFyRtJHXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest classifier \n",
        "\n",
        "# Import the necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql.functions import when\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"CarEvaluation_RF\").getOrCreate()\n",
        "\n",
        "# Read the data from the CSV files\n",
        "data1 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/car_evaluation_0.csv\")\n",
        "data2 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/car_evaluation_1.csv\")\n",
        "data3 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/car_evaluation_2.csv\")\n",
        "data4 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/car_evaluation_3.csv\")\n",
        "\n",
        "# Combine the data frames into a single data frame\n",
        "data = data1.union(data2).union(data3).union(data4)\n",
        "\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(data) for column in ['buyPrice', 'maintCost', \n",
        "                                                                                               'noDoors', 'noPersons', 'bootLuggage', 'safety', 'decision']]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "indexed_data = pipeline.fit(data).transform(data)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "(trainingData, testData) = indexed_data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Create the feature vector by combining all input features using VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=['buyPrice_index', 'maintCost_index', 'noDoors_index', 'noPersons_index', 'bootLuggage_index', 'safety_index'], outputCol='features')\n",
        "trainingData = assembler.transform(trainingData)\n",
        "testData = assembler.transform(testData)\n",
        "\n",
        "# Create the Random Forest Classifier\n",
        "rf = RandomForestClassifier(labelCol=\"decision_index\", featuresCol=\"features\")\n",
        "\n",
        "# Train the model\n",
        "model = rf.fit(trainingData)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Convert the predicted indexes to corresponding class labels\n",
        "predictions = predictions.withColumn(\"predicted_class\", when(predictions[\"prediction\"] == 0,\"Unacceptable\").when(predictions[\"prediction\"] == 1, \"Acceptable\").when(predictions[\"prediction\"] == 2, \"Good\").otherwise(\"Very Good\"))\n",
        "# Print the data with the predicted classes\n",
        "predictions.select(\"buyPrice\", \"maintCost\", \"noDoors\", \"noPersons\", \"bootLuggage\", \"safety\", \"decision\", \"predicted_class\").show(5)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"decision_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL-xGeMMQW2Z",
        "outputId": "72298030-8243-40ff-8237-a5cdff3e567b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------+---------+-----------+------+--------+---------------+\n",
            "|buyPrice|maintCost|noDoors|noPersons|bootLuggage|safety|decision|predicted_class|\n",
            "+--------+---------+-------+---------+-----------+------+--------+---------------+\n",
            "|   vhigh|     high|      2|        2|        big|   low|   unacc|   Unacceptable|\n",
            "|   vhigh|     high|      2|        2|        med|   med|   unacc|   Unacceptable|\n",
            "|   vhigh|     high|      2|        2|      small|   low|   unacc|   Unacceptable|\n",
            "|   vhigh|     high|      2|        2|      small|   med|   unacc|   Unacceptable|\n",
            "|   vhigh|     high|      2|        4|        med|  high|   unacc|   Unacceptable|\n",
            "+--------+---------+-------+---------+-----------+------+--------+---------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy: 90.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yDtfuMyC2vG",
        "outputId": "a69b05f1-726b-43d8-814f-d0d6c6b21c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------+---------+-----------+------+--------+---------------+\n",
            "|buyPrice|maintCost|noDoors|noPersons|bootLuggage|safety|decision|predicted_class|\n",
            "+--------+---------+-------+---------+-----------+------+--------+---------------+\n",
            "|   vhigh|     high|      2|        2|        big|   low|   unacc|   Unacceptable|\n",
            "|   vhigh|     high|      2|        2|        med|   med|   unacc|   Unacceptable|\n",
            "|   vhigh|     high|      2|        2|      small|   low|   unacc|   Unacceptable|\n",
            "|   vhigh|     high|      2|        2|      small|   med|   unacc|   Unacceptable|\n",
            "|   vhigh|     high|      2|        4|        med|  high|   unacc|   Unacceptable|\n",
            "+--------+---------+-------+---------+-----------+------+--------+---------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy: 86.48%\n"
          ]
        }
      ],
      "source": [
        "#Decision tree\n",
        "\n",
        "# Import the necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.sql.functions import when\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"CarEvaluation_DT\").getOrCreate()\n",
        "\n",
        "# Read the data from the CSV files\n",
        "data1 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/car_evaluation_0.csv\")\n",
        "data2 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/car_evaluation_1.csv\")\n",
        "data3 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/car_evaluation_2.csv\")\n",
        "data4 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/car_evaluation_3.csv\")\n",
        "\n",
        "# Combine the data frames into a single data frame\n",
        "data = data1.union(data2).union(data3).union(data4)\n",
        "\n",
        "\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(data) for column in ['buyPrice', 'maintCost','noDoors', 'noPersons', 'bootLuggage', 'safety', 'decision']]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "indexed_data = pipeline.fit(data).transform(data)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "(trainingData, testData) = indexed_data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Create the feature vector by combining all input features using VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=['buyPrice_index', 'maintCost_index', 'noDoors_index', 'noPersons_index', 'bootLuggage_index', 'safety_index'], outputCol='features')\n",
        "trainingData = assembler.transform(trainingData)\n",
        "testData = assembler.transform(testData)\n",
        "\n",
        "# Create the Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(labelCol=\"decision_index\", featuresCol=\"features\")\n",
        "\n",
        "# Train the model\n",
        "model = dt.fit(trainingData)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Convert the predicted indexes to corresponding class labels\n",
        "predictions = predictions.withColumn(\"predicted_class\", when(predictions[\"prediction\"] == 0,\"Unacceptable\").when(predictions[\"prediction\"] == 1, \"Acceptable\").when(predictions[\"prediction\"] == 2, \"Good\").otherwise(\"Very Good\"))\n",
        "\n",
        "# Print the data with the predicted classes\n",
        "predictions.select(\"buyPrice\", \"maintCost\", \"noDoors\", \"noPersons\", \"bootLuggage\", \"safety\", \"decision\", \"predicted_class\").show(5)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"decision_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()"
      ]
    }
  ]
}